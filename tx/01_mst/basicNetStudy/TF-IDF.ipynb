{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = ['Then Saint Peter came with the key', 'and opened the door','and let the great man in','butapparently did not see the peasant','and shut the door again','And now the peasant outside','heard how the great man was received in heaven with all kinds of rejoicing','and how they were making music','and singing within','At length all became quiet again','and Saint Peter came and opened the gate of heaven','and let the peasant in.']\n",
    "arr2 = ['So he left neighbourhood of the altars','where he got his living by picking up bits of the meat offered in sacrifice','and went and lived among the pools and streams.']\n",
    "arr3 = ['A Stag. Blind of one eye','was grazing close to the sea-shore and kept his sound eye turned towards the land','so as to be able to perceive the approach of the hounds','while the blind eye he turned towards the sea','never suspecting that any danger would threaten him from that quarter.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词袋法\n",
    "count = CountVectorizer(min_df=0.1,dtype=np.float64,ngram_range=(0,1))\n",
    "df1 = count.fit_transform(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.]]\n",
      "None\n",
      "['again' 'all' 'and' 'came' 'door' 'great' 'heaven' 'how' 'in' 'let' 'man'\n",
      " 'of' 'opened' 'peasant' 'peter' 'saint' 'the' 'with']\n"
     ]
    }
   ],
   "source": [
    "print(df1.toarray())\n",
    "print(count.get_stop_words())\n",
    "print(count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      "  1.]\n",
      " [0. 1. 3. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      "  0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      "  1. 0. 1. 0. 0. 0. 2. 0. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 1. 2. 0. 1. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(count.fit_transform(arr2).toarray())\n",
    "print(count.fit_transform(arr3).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.48438915 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.48438915 0.48438915 0.24792862 0.48438915]\n",
      " [0.         0.         0.34595611 0.         0.62384216 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.62384216 0.         0.         0.         0.31930593 0.        ]\n",
      " [0.         0.         0.26589498 0.         0.         0.47947266\n",
      "  0.         0.         0.42354531 0.47947266 0.47947266 0.\n",
      "  0.         0.         0.         0.         0.24541218 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.86524753 0.         0.         0.5013449  0.        ]\n",
      " [0.62384216 0.         0.34595611 0.         0.62384216 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.31930593 0.        ]\n",
      " [0.         0.         0.47731679 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.76032008 0.         0.         0.44054745 0.        ]\n",
      " [0.         0.35262245 0.         0.         0.         0.35262245\n",
      "  0.35262245 0.35262245 0.31149135 0.         0.35262245 0.35262245\n",
      "  0.         0.         0.         0.         0.18048546 0.35262245]\n",
      " [0.         0.         0.48497556 0.         0.         0.\n",
      "  0.         0.8745277  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.70710678 0.70710678 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.40520439 0.36534054 0.         0.\n",
      "  0.36534054 0.         0.         0.         0.         0.36534054\n",
      "  0.36534054 0.         0.36534054 0.36534054 0.18699506 0.        ]\n",
      " [0.         0.         0.31344676 0.         0.         0.\n",
      "  0.         0.         0.49929076 0.56521997 0.         0.\n",
      "  0.         0.49929076 0.         0.         0.28930088 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_t = TfidfTransformer()\n",
    "df2 = tfidf_t.fit_transform(df1)\n",
    "print(df2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.56801408 0.         0.         0.         0.         0.\n",
      "  0.         0.45827018 0.         0.         0.         0.\n",
      "  0.         0.56801408 0.         0.         0.         0.\n",
      "  0.38040565 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.56801408 0.         0.56801408 0.         0.         0.\n",
      "  0.         0.45827018 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38040565 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.97597683 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21787435 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TF+IDF\n",
    "tfidf_v = TfidfVectorizer(min_df=0.1,dtype=np.float64)\n",
    "tfidf_v.fit(arr1)\n",
    "tfidf_v.fit(arr2)\n",
    "tfidf_v.fit(arr3)\n",
    "print(tfidf_v.transform(arr2).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['able' 'and' 'any' 'approach' 'as' 'be' 'blind' 'close' 'danger' 'eye'\n",
      " 'from' 'grazing' 'he' 'him' 'his' 'hounds' 'kept' 'land' 'never' 'of'\n",
      " 'one' 'perceive' 'quarter' 'sea' 'shore' 'so' 'sound' 'stag' 'suspecting'\n",
      " 'that' 'the' 'threaten' 'to' 'towards' 'turned' 'was' 'while' 'would']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_v.get_stop_words())\n",
    "print(tfidf_v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
